{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1 -working with local html file to extract some information\n",
    "with open('Freecodecamphtmlsite.html','r') as html_file:\n",
    "    content = html_file.read()\n",
    "    \n",
    "    \n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    \n",
    "    #searching for all header h5 tags \n",
    "    #first_header_tags=soup.find('h5') #finds the first element\n",
    "    #all_header_tags=soup.find_all('h5')#finds a list of all tags \n",
    "    \n",
    "    #to print the results to text#in this case courses list \n",
    "    \n",
    "    #for course in all_header_tags:\n",
    "        #print(course.get_txt())\n",
    "    course_cards = soup.find_all('div',class_='card')   #underscore since class is a keyword already\n",
    "    \n",
    "    #code to print course and prices \n",
    "    for course in course_cards:\n",
    "        course_name = course.h5.get_text().strip()\n",
    "        course_price = course.a.get_text().strip()[10:-1]\n",
    "        print(course_name, course_price)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put some skill that you are not familiar with\n",
      ">django\n",
      "Filtering out django\n",
      "File saved: 3\n",
      "File saved: 13\n",
      "File saved: 14\n",
      "File saved: 15\n",
      "File saved: 20\n",
      "waiting1 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-430577dbcb5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mtime_wait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'waiting{time_wait} minutes...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_wait\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m#Additional functionalities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#PART 2 - scraping from a real website with the requests library \n",
    "#scraping job advertisements requiring python prohramming only a few days ago\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "import requests  #for requesting information from the site \n",
    "import time\n",
    "\n",
    "    \n",
    "print('Put some skill that you are not familiar with')\n",
    "\n",
    "unfamiliar_skill=input('>')\n",
    "   \n",
    "    \n",
    "print(f'Filtering out {unfamiliar_skill}')\n",
    "\n",
    "def find_jobs():\n",
    "    html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=').text   #url to scrape from \n",
    "\n",
    "    # parsing the html\n",
    "\n",
    "    soup = BeautifulSoup(html_text,'lxml')\n",
    "    jobs  =soup.find_all('li',class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "     #to collect only a specific date range\n",
    "        #additional span tag scanning needed to find the job text\n",
    "    for index,job in enumerate(jobs):\n",
    "        published_date=job.find('span',class_='sim-posted').span.text\n",
    "        if 'few' in published_date:\n",
    "\n",
    "            #to search for the tag with the names and jobs only inside the job \n",
    "            #replace spaces\n",
    "            company_name=job.find('h3',class_='joblist-comp-name').text.replace(' ','')      \n",
    "            skills=job.find('span',class_='srp-skills').text.replace(' ','') \n",
    "            more_info=job.header.h2.a['href']       #to see the link only\n",
    "\n",
    "            #search job for list of unfamiliar skills\n",
    "\n",
    "            if unfamiliar_skill[p] not in skills:\n",
    "                    with open(f'posts/{index}.txt','w') as f:\n",
    "                        f.write(f\"Company name: {company_name.strip()}\\n\")\n",
    "                        f.write(f\"Required Skills: {skills.strip()}\\n\")\n",
    "                        f.write(f\"more_info: {more_info}\")\n",
    "                    print(f'File saved: {index}')\n",
    "                    \n",
    "#putting all in a function                   \n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait=1\n",
    "        print(f'waiting {time_wait} minute...')\n",
    "        time.sleep(time_wait*360)\n",
    "\n",
    "#Additional functionalities \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "css\n"
     ]
    }
   ],
   "source": [
    "print(unfamiliar_skill[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
